name: Codex Global CI

on:
  push:
    branches: ['*']
  pull_request:
  workflow_dispatch:

permissions:
  contents: read
  checks: write
  statuses: write

env:
  CODEX_CD_ENABLED: ${{ vars.CODEX_CD_ENABLED || 'false' }}
  CODEX_CD_BRANCH: ${{ vars.CODEX_CD_BRANCH || 'main' }}
  CODEX_CD_TARGET: ${{ vars.CODEX_CD_TARGET || '' }}
  CODEX_CD_ALLOW_TAGS: ${{ vars.CODEX_CD_ALLOW_TAGS || 'true' }}

concurrency:
  group: codex-${{ github.repository }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    runs-on: ubuntu-latest
    outputs:
      docs_only: ${{ steps.analyse.outputs.docs_only }}
      no_changes: ${{ steps.analyse.outputs.no_changes }}
      changed_files: ${{ steps.analyse.outputs.changed_files }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: analyse
        run: |
          set -eo pipefail
          base=""
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            base="${{ github.event.pull_request.base.sha }}"
          else
            base="${{ github.event.before }}"
          fi
          if [ -z "$base" ]; then
            base=$(git rev-list --max-count=1 HEAD^ 2>/dev/null || echo "")
          fi
          if [ -n "$base" ]; then
            git diff --name-only "$base" HEAD > changed.txt || true
          else
            git diff --name-only HEAD^ HEAD > changed.txt || true
          fi
          if [ ! -s changed.txt ]; then
            echo "no_changes=true" >> "$GITHUB_OUTPUT"
            echo "docs_only=false" >> "$GITHUB_OUTPUT"
            echo "changed_files=[]" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "no_changes=false" >> "$GITHUB_OUTPUT"
          changed_json=$(python - <<'PY'
import json
paths=[line.strip() for line in open('changed.txt') if line.strip()]
print(json.dumps(paths))
PY
)
          echo "changed_files=${changed_json}" >> "$GITHUB_OUTPUT"
          docs_only=true
          while IFS= read -r path; do
            case "$path" in
              docs/*|doc/*|documentation/*|*.md|*.rst|*.txt|*.adoc|*.po|*.pot|LICENSE|LICENSE.*|README|README.*|CHANGELOG*|.github/ISSUE_TEMPLATE/*|.github/PULL_REQUEST_TEMPLATE.*)
                ;;
              *)
                docs_only=false
                break
                ;;
            esac
          done < changed.txt
          echo "docs_only=${docs_only}" >> "$GITHUB_OUTPUT"
  detect:
    runs-on: ubuntu-latest
    needs: changes
    outputs:
      languages: ${{ steps.collect.outputs.languages }}
      has_python: ${{ steps.collect.outputs.has_python }}
      has_node: ${{ steps.collect.outputs.has_node }}
      has_go: ${{ steps.collect.outputs.has_go }}
      has_rust: ${{ steps.collect.outputs.has_rust }}
      has_terraform: ${{ steps.collect.outputs.has_terraform }}
      has_docker: ${{ steps.collect.outputs.has_docker }}
      python_manager: ${{ steps.collect.outputs.python_manager }}
      node_pm: ${{ steps.collect.outputs.node_pm }}
      has_cd: ${{ steps.collect.outputs.has_cd }}
      has_deploy_hooks: ${{ steps.collect.outputs.has_deploy_hooks }}
      deploy_hook_count: ${{ steps.collect.outputs.deploy_hook_count }}
      has_ci_config: ${{ steps.collect.outputs.has_ci_config }}
      has_ci_hooks: ${{ steps.collect.outputs.has_ci_hooks }}
      ci_hook_count: ${{ steps.collect.outputs.ci_hook_count }}
      required_secrets: ${{ steps.collect.outputs.required_secrets }}
      required_secrets_count: ${{ steps.collect.outputs.required_secrets_count }}
      python_versions: ${{ steps.collect.outputs.python_versions }}
      node_versions: ${{ steps.collect.outputs.node_versions }}
      ci_matrix: ${{ steps.collect.outputs.ci_matrix }}
      deploy_enabled: ${{ steps.collect.outputs.deploy_enabled }}
      hooks_ci_enabled: ${{ steps.collect.outputs.hooks_ci_enabled }}
      hooks_deploy_enabled: ${{ steps.collect.outputs.hooks_deploy_enabled }}
      skip_ci: ${{ steps.collect.outputs.skip_ci }}
      pruned_languages: ${{ steps.collect.outputs.pruned_languages }}
      python_touched: ${{ steps.collect.outputs.python_touched }}
      node_touched: ${{ steps.collect.outputs.node_touched }}
      go_touched: ${{ steps.collect.outputs.go_touched }}
      rust_touched: ${{ steps.collect.outputs.rust_touched }}
      terraform_touched: ${{ steps.collect.outputs.terraform_touched }}
      docker_touched: ${{ steps.collect.outputs.docker_touched }}
      force_ci: ${{ steps.collect.outputs.force_ci }}
      skip_reason: ${{ steps.collect.outputs.skip_reason }}
    steps:
      - uses: actions/checkout@v4
      - id: collect
        env:
          CODEX_DOCS_ONLY: ${{ needs.changes.outputs.docs_only }}
          CODEX_NO_CHANGES: ${{ needs.changes.outputs.no_changes }}
          CODEX_CHANGED_FILES: ${{ needs.changes.outputs.changed_files }}
          CODEX_FORCE_CI: ${{ (vars.CODEX_FORCE_CI == 'true' || github.event_name == 'workflow_dispatch' || (github.event_name == 'pull_request' && contains(join(github.event.pull_request.labels.*.name, ' '), 'ci:force')) || contains(github.event.head_commit.message || '', '[force ci]')) && 'true' || 'false' }}
        run: |
          python - <<'PY'
          import json
          import os
          import pathlib
          import fnmatch

          root = pathlib.Path(".")
          config_path = root / ".codex/ci/config.json"

          def exists(*names):
              return any((root / name).exists() for name in names)

          config = {}
          config_errors: list[str] = []
          if config_path.exists():
              try:
                  config = json.loads(config_path.read_text(encoding="utf-8"))
              except Exception as exc:
                  config_errors.append(f"config parse error: {exc}")
                  config = {}

          def config_bool(path: str, default: bool) -> bool:
              data = config
              for part in path.split("."):
                  if isinstance(data, dict):
                      data = data.get(part)
                  else:
                      data = None
              return data if isinstance(data, bool) else default

          def config_list(path: str) -> list[str]:
              data = config
              for part in path.split("."):
                  if isinstance(data, dict):
                      data = data.get(part)
                  else:
                      data = None
              if isinstance(data, list):
                  items: list[str] = []
                  seen = set()
                  for entry in data:
                      value = str(entry).strip()
                      if not value or value in seen:
                          continue
                      seen.add(value)
                      items.append(value)
                  return items
              return []

          has_python = exists("pyproject.toml", "requirements.txt", "Pipfile", "setup.cfg")
          has_node = (root / "package.json").exists()
          has_go = (root / "go.mod").exists()
          has_rust = (root / "Cargo.toml").exists()
          has_terraform = any(root.glob("**/*.tf"))
          has_docker = exists("Dockerfile", "docker-compose.yml", "compose.yml")

          python_manager = ""
          if has_python:
              if exists("uv.lock", "uv.toml"):
                  python_manager = "uv"
              elif (root / "poetry.lock").exists():
                  python_manager = "poetry"
              elif (root / "Pipfile").exists():
                  python_manager = "pipenv"
              else:
                  python_manager = "pip"

          node_pm = ""
          if has_node:
              if (root / "pnpm-lock.yaml").exists():
                  node_pm = "pnpm"
              elif (root / "yarn.lock").exists():
                  node_pm = "yarn"
              elif exists("package-lock.json", "npm-shrinkwrap.json"):
                  node_pm = "npm"
              else:
                  node_pm = "npm"

          python_enabled = has_python and config_bool("python.enable", True)
          node_enabled = has_node and config_bool("node.enable", True)
          go_enabled = has_go and config_bool("go.enable", True)
          rust_enabled = has_rust and config_bool("rust.enable", True)
          terraform_enabled = has_terraform and config_bool("terraform.enable", True)
          docker_enabled = has_docker and config_bool("docker.lint", True)

          if not python_enabled:
              python_manager = ""
          if not node_enabled:
              node_pm = ""

          deploy_script_exists = (root / ".codex/ci/auto-deploy.sh").exists()
          deploy_enabled = config_bool("deploy.enable", True) and deploy_script_exists

          hooks_ci_enabled = config_bool("hooks.ci", True)
          hooks_deploy_enabled = config_bool("hooks.deploy", True)

          deploy_hooks = sorted(p.name for p in (root / ".codex/ci/deploy.d").glob("*.sh"))
          deploy_hook_count = len(deploy_hooks)
          has_deploy_hooks = deploy_enabled and hooks_deploy_enabled and deploy_hook_count > 0

          ci_hooks = sorted(p.name for p in (root / ".codex/ci/ci.d").glob("*.sh"))
          ci_hook_count = len(ci_hooks)
          has_ci_hooks = hooks_ci_enabled and ci_hook_count > 0

          required_secrets = []
          secrets_cfg = config.get("secrets", {}) if isinstance(config, dict) else {}
          if isinstance(secrets_cfg, dict):
              required = secrets_cfg.get("required", [])
              if isinstance(required, list):
                  for entry in required:
                      value = str(entry).strip()
                      if value:
                          required_secrets.append(value)

          force_patterns = config_list("ci.force_paths")
          if not force_patterns:
              force_patterns = [".codex/ci/**", ".github/workflows/**"]

          always_run = {item.lower() for item in config_list("ci.always_run")}
          max_parallel_config = config.get("ci", {}).get("max_parallel") if isinstance(config, dict) else None
          try:
              max_parallel_value = int(max_parallel_config)
              if max_parallel_value <= 0:
                  raise ValueError
          except Exception:
              max_parallel_value = None

          fail_fast = config_bool("ci.fail_fast", True)

          changed_files_json = os.environ.get("CODEX_CHANGED_FILES", "[]")
          try:
              changed_files = json.loads(changed_files_json)
              if not isinstance(changed_files, list):
                  changed_files = []
          except json.JSONDecodeError:
              changed_files = []

          force_ci_env = os.environ.get("CODEX_FORCE_CI", "false").lower() == "true"

          def lang_targets(name: str) -> list[str]:
              return config_list(f"targets.{name}")

          python_targets = lang_targets("python")
          node_targets = lang_targets("node")
          go_targets = lang_targets("go")
          rust_targets = lang_targets("rust")
          terraform_targets = lang_targets("terraform")
          docker_targets = lang_targets("docker")

          force_from_paths = False
          if changed_files:
              for path in changed_files:
                  if any(fnmatch.fnmatch(path, pattern) for pattern in force_patterns):
                      force_from_paths = True
                      break

          python_versions = config_list("python.versions") if python_enabled else []
          if python_enabled and not python_versions:
              python_versions = ["3.x"]
          node_versions = config_list("node.versions") if node_enabled else []
          if node_enabled and not node_versions:
              node_versions = ["lts"]

          python_matrix = python_versions if python_enabled else [""]
          node_matrix = node_versions if node_enabled else [""]

          skip_ci = False
          if no_changes_env:
              skip_ci = True
          elif docs_only_env and skip_docs_only:
              skip_ci = True

          if force_ci_env or force_from_paths:
              skip_ci = False

          def is_language_touched(enabled: bool, targets: list[str]) -> bool:
              if not enabled:
                  return False
              if force_ci_env or force_from_paths:
                  return True
              if not changed_files:
                  return True
              if not targets:
                  return True
              for path in changed_files:
                  for pattern in targets:
                      if fnmatch.fnmatch(path, pattern):
                          return True
              return False

          pruned_languages = []

          python_touched = is_language_touched(python_enabled, python_targets)
          if python_enabled and not (python_touched or "python" in always_run):
              python_enabled = False
              pruned_languages.append("python")

          node_touched = is_language_touched(node_enabled, node_targets)
          if node_enabled and not (node_touched or "node" in always_run):
              node_enabled = False
              pruned_languages.append("node")

          go_touched = is_language_touched(go_enabled, go_targets)
          if go_enabled and not (go_touched or "go" in always_run):
              go_enabled = False
              pruned_languages.append("go")

          rust_touched = is_language_touched(rust_enabled, rust_targets)
          if rust_enabled and not (rust_touched or "rust" in always_run):
              rust_enabled = False
              pruned_languages.append("rust")

          terraform_touched = is_language_touched(terraform_enabled, terraform_targets)
          if terraform_enabled and not (terraform_touched or "terraform" in always_run):
              terraform_enabled = False
              pruned_languages.append("terraform")

          docker_touched = is_language_touched(docker_enabled, docker_targets)
          if docker_enabled and not (docker_touched or "docker" in always_run):
              docker_enabled = False
              pruned_languages.append("docker")

          if not any([python_enabled, node_enabled, go_enabled, rust_enabled, terraform_enabled, docker_enabled]):
              skip_ci = True

          matrix_entries = []
          if not skip_ci:
              seen_keys = set()
              for py in python_matrix:
                  py_value = py if python_enabled else ""
                  for node in node_matrix:
                      node_value = node if node_enabled else ""
                      label_parts = []
                      if python_enabled and py_value:
                          label_parts.append(f"py{py_value}")
                      if node_enabled and node_value:
                          label_parts.append(f"node{node_value}")
                      if not label_parts:
                          label_parts.append("default")
                      entry = {"python": py_value, "node": node_value, "label": "-".join(label_parts)}
                      key = (entry["python"], entry["node"])
                      if key in seen_keys:
                          continue
                      seen_keys.add(key)
                      matrix_entries.append(entry)
              if not matrix_entries:
                  matrix_entries = [{"python": "", "node": "", "label": "default"}]

          languages = []
          if python_enabled:
              languages.append("python")
          if node_enabled:
              languages.append("node")
          if go_enabled:
              languages.append("go")
          if rust_enabled:
              languages.append("rust")
          if terraform_enabled:
              languages.append("terraform")
          if docker_enabled:
              languages.append("docker")

          if skip_ci:
              if no_changes_env:
                  skip_reason = "no_changes"
              elif docs_only_env and skip_docs_only and not (force_ci_env or force_from_paths):
                  skip_reason = "docs_only"
              elif not languages:
                  skip_reason = "no_matching_targets"
              else:
                  skip_reason = "config"
          else:
              skip_reason = ""

          outputs = {
              "languages": ",".join(languages),
              "has_python": "true" if python_enabled else "false",
              "has_node": "true" if node_enabled else "false",
              "has_go": "true" if go_enabled else "false",
              "has_rust": "true" if rust_enabled else "false",
              "has_terraform": "true" if terraform_enabled else "false",
              "has_docker": "true" if docker_enabled else "false",
              "python_manager": python_manager,
              "node_pm": node_pm,
              "has_cd": "true" if deploy_enabled else "false",
              "has_deploy_hooks": "true" if has_deploy_hooks else "false",
              "deploy_hook_count": str(deploy_hook_count),
              "has_ci_config": "true" if config_path.exists() else "false",
              "has_ci_hooks": "true" if has_ci_hooks else "false",
              "ci_hook_count": str(ci_hook_count),
              "required_secrets": ",".join(required_secrets),
              "required_secrets_count": str(len(required_secrets)),
              "python_versions": json.dumps(python_versions, separators=(',', ':')),
              "node_versions": json.dumps(node_versions, separators=(',', ':')),
              "ci_matrix": json.dumps(matrix_entries, separators=(',', ':')),
              "deploy_enabled": "true" if deploy_enabled else "false",
              "hooks_ci_enabled": "true" if hooks_ci_enabled else "false",
              "hooks_deploy_enabled": "true" if hooks_deploy_enabled else "false",
              "skip_ci": "true" if skip_ci else "false",
              "changed_files": json.dumps(changed_files, separators=(',', ':')),
              "python_touched": "true" if python_touched else "false",
              "node_touched": "true" if node_touched else "false",
              "go_touched": "true" if go_touched else "false",
              "rust_touched": "true" if rust_touched else "false",
              "terraform_touched": "true" if terraform_touched else "false",
              "docker_touched": "true" if docker_touched else "false",
              "force_ci": "true" if (force_ci_env or force_from_paths) else "false",
              "pruned_languages": json.dumps(pruned_languages, separators=(',', ':')),
              "skip_reason": skip_reason,
              "max_parallel": json.dumps(max_parallel_value) if max_parallel_value is not None else "",
              "fail_fast": "true" if fail_fast else "false",
          }

          output_path = pathlib.Path(os.environ["GITHUB_OUTPUT"])
          with output_path.open("a", encoding="utf-8") as fh:
              for key, value in outputs.items():
                  fh.write(f"{key}={value}\n")

          summary_lines = [
              "# Codex Detect Summary",
              "",
              f"*Languages:* {', '.join(languages) if languages else 'none'}",
              f"*Python enabled:* {python_enabled}",
              f"*Node enabled:* {node_enabled}",
              f"*Go enabled:* {go_enabled}",
              f"*Rust enabled:* {rust_enabled}",
              f"*Terraform enabled:* {terraform_enabled}",
              f"*Docker lint enabled:* {docker_enabled}",
              f"*Deploy enabled:* {deploy_enabled}",
              f"*CI hooks enabled:* {hooks_ci_enabled}",
              f"*Deploy hooks enabled:* {hooks_deploy_enabled}",
              f"*Required secrets:* {', '.join(required_secrets) if required_secrets else 'none'}",
              f"*Changed files:* {', '.join(changed_files) if changed_files else 'n/a'}",
          ]
          if max_parallel_value is not None:
              summary_lines.append(f"*Matrix max_parallel:* {max_parallel_value}")
          summary_lines.append(f"*Fail fast:* {fail_fast}")
          if pruned_languages:
              summary_lines.append(f"*Languages pruned by change filters:* {', '.join(pruned_languages)}")
          summary_lines.extend([
              "",
              "| Matrix Label | Python | Node |",
              "| --- | --- | --- |",
          ])
          for entry in matrix_entries:
              summary_lines.append(f"| {entry['label']} | {entry['python'] or 'n/a'} | {entry['node'] or 'n/a'} |")
          if config_errors:
              summary_lines.append("")
              summary_lines.append("**Config warnings:**")
              for err in config_errors:
                  summary_lines.append(f"- {err}")
          if skip_ci:
              summary_lines.append("")
              if skip_reason == "no_changes":
                  summary_lines.append("CI matrix skipped: no changes detected.")
              elif skip_reason == "docs_only":
                  summary_lines.append("CI matrix skipped: docs-only changes and skip_docs_only enabled.")
              elif skip_reason == "no_matching_targets":
                  summary_lines.append("CI matrix skipped: no language targets matched changed files.")
              else:
                  summary_lines.append("CI matrix skipped by configuration.")
          elif force_ci_env:
              summary_lines.append("")
              summary_lines.append("CI executed due to CODEX_FORCE_CI override.")
          elif force_from_paths:
              summary_lines.append("")
              summary_lines.append("CI executed because changed files matched force paths.")
          summary_path = pathlib.Path("detect-summary.md")
          summary_path.write_text("\n".join(summary_lines), encoding="utf-8")
          PY
      - name: Publish detection summary
        if: always()
        run: |
          if [ -f detect-summary.md ]; then
            cat detect-summary.md >> "$GITHUB_STEP_SUMMARY"
          fi
  auto-ci:
    needs: detect
    runs-on: ubuntu-latest
    strategy:
      fail-fast: ${{ needs.detect.outputs.fail_fast == 'true' }}
      max-parallel: ${{ needs.detect.outputs.max_parallel != '' && fromJson(needs.detect.outputs.max_parallel) || 4 }}
      matrix: ${{ fromJson(needs.detect.outputs.ci_matrix) }}
    if: needs.detect.outputs.skip_ci != 'true'
    env:
      CODEX_CI_LANGUAGES: ${{ needs.detect.outputs.languages }}
      CODEX_CI_HAS_PYTHON: ${{ needs.detect.outputs.has_python }}
      CODEX_CI_HAS_NODE: ${{ needs.detect.outputs.has_node }}
      CODEX_CI_HAS_GO: ${{ needs.detect.outputs.has_go }}
      CODEX_CI_HAS_RUST: ${{ needs.detect.outputs.has_rust }}
      CODEX_CI_HAS_TERRAFORM: ${{ needs.detect.outputs.has_terraform }}
      CODEX_CI_HAS_DOCKER: ${{ needs.detect.outputs.has_docker }}
      CODEX_CI_PYTHON_MANAGER: ${{ needs.detect.outputs.python_manager }}
      CODEX_CI_NODE_PM: ${{ needs.detect.outputs.node_pm }}
      CODEX_CI_HAS_CD: ${{ needs.detect.outputs.has_cd }}
      CODEX_CI_HAS_DEPLOY_HOOKS: ${{ needs.detect.outputs.has_deploy_hooks }}
      CODEX_CI_DEPLOY_HOOK_COUNT: ${{ needs.detect.outputs.deploy_hook_count }}
      CODEX_CI_HAS_CI_CONFIG: ${{ needs.detect.outputs.has_ci_config }}
      CODEX_CI_HAS_HOOKS: ${{ needs.detect.outputs.has_ci_hooks }}
      CODEX_CI_HOOK_COUNT: ${{ needs.detect.outputs.ci_hook_count }}
      CODEX_CI_REQUIRED_SECRETS: ${{ needs.detect.outputs.required_secrets }}
      CODEX_CI_REQUIRED_SECRETS_COUNT: ${{ needs.detect.outputs.required_secrets_count }}
      CODEX_CI_MATRIX_LABEL: ${{ matrix.label }}
      CODEX_CI_PYTHON_VERSION: ${{ matrix.python }}
      CODEX_CI_NODE_VERSION: ${{ matrix.node }}
      CODEX_CHANGED_FILES_JSON: ${{ needs.detect.outputs.changed_files }}
      CODEX_CI_PYTHON_TOUCHED: ${{ needs.detect.outputs.python_touched }}
      CODEX_CI_NODE_TOUCHED: ${{ needs.detect.outputs.node_touched }}
      CODEX_CI_GO_TOUCHED: ${{ needs.detect.outputs.go_touched }}
      CODEX_CI_RUST_TOUCHED: ${{ needs.detect.outputs.rust_touched }}
      CODEX_CI_TERRAFORM_TOUCHED: ${{ needs.detect.outputs.terraform_touched }}
      CODEX_CI_DOCKER_TOUCHED: ${{ needs.detect.outputs.docker_touched }}
      CODEX_CI_PRUNED_LANGUAGES: ${{ needs.detect.outputs.pruned_languages }}
      CODEX_CI_FORCE_CI: ${{ needs.detect.outputs.force_ci }}
      CODEX_CI_SKIP_REASON: ${{ needs.detect.outputs.skip_reason }}
      CODEX_CD_ENABLED: ${{ env.CODEX_CD_ENABLED }}
      CODEX_CD_BRANCH: ${{ env.CODEX_CD_BRANCH }}
      CODEX_CD_TARGET: ${{ env.CODEX_CD_TARGET }}
      CODEX_CD_ALLOW_TAGS: ${{ env.CODEX_CD_ALLOW_TAGS }}
    steps:
      - uses: actions/checkout@v4
      - name: Matrix context
        run: |
          echo "Matrix label: ${CODEX_CI_MATRIX_LABEL}"
          echo "Python version: ${CODEX_CI_PYTHON_VERSION:-<none>}"
          echo "Node version: ${CODEX_CI_NODE_VERSION:-<none>}"
      - name: Set up Node
        if: env.CODEX_CI_HAS_NODE == 'true' && env.CODEX_CI_NODE_VERSION != ''
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node }}
          check-latest: true
          cache: ${{ env.CODEX_CI_NODE_PM == 'pnpm' && 'pnpm' || env.CODEX_CI_NODE_PM == 'yarn' && 'yarn' || 'npm' }}
          cache-dependency-path: |
            pnpm-lock.yaml
            yarn.lock
            package-lock.json
            npm-shrinkwrap.json
      - name: Enable Corepack
        if: env.CODEX_CI_HAS_NODE == 'true' && env.CODEX_CI_NODE_VERSION != ''
        run: corepack enable
      - name: Set up Python
        if: env.CODEX_CI_HAS_PYTHON == 'true' && env.CODEX_CI_PYTHON_VERSION != ''
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}
          cache: ${{ env.CODEX_CI_PYTHON_MANAGER == 'poetry' && 'poetry' || env.CODEX_CI_PYTHON_MANAGER == 'pipenv' && 'pipenv' || 'pip' }}
          cache-dependency-path: |
            pyproject.toml
            requirements.txt
            Pipfile
            poetry.lock
      - name: Set up Go
        if: env.CODEX_CI_HAS_GO == 'true'
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'
      - name: Set up Rust
        if: env.CODEX_CI_HAS_RUST == 'true'
        uses: dtolnay/rust-toolchain@stable
      - name: Ensure script executable
        run: chmod +x .codex/ci/auto-ci.sh
      - name: Run Codex automation suite
        run: ./.codex/ci/auto-ci.sh
      - name: Publish CI summary
        if: always()
        run: |
          if [ -f .codex/ci/report.md ]; then
            {
              echo "### Codex CI (${CODEX_CI_MATRIX_LABEL})"
              echo ""
              cat .codex/ci/report.md
            } >> "$GITHUB_STEP_SUMMARY"
          else
            echo "Codex CI harness did not produce a markdown summary." >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload log artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: codex-ci-${{ matrix.label }}
          path: |
            .codex/ci/**/*.log
            .codex/ci/**/*.json
        continue-on-error: true
  report:
    needs:
      - detect
      - auto-ci
    runs-on: ubuntu-latest
    outputs:
      overall: ${{ steps.aggregate.outputs.overall }}
      failed: ${{ steps.aggregate.outputs.failed }}
      missing: ${{ steps.aggregate.outputs.missing }}
      skip_ci: ${{ steps.aggregate.outputs.skip_ci }}
      skip_reason: ${{ steps.aggregate.outputs.skip_reason }}
      pruned_languages: ${{ steps.aggregate.outputs.pruned_languages }}
      total_duration_seconds: ${{ steps.aggregate.outputs.total_duration_seconds }}
      flaky_steps: ${{ steps.aggregate.outputs.flaky_steps }}
      total_duration_seconds: ${{ steps.aggregate.outputs.total_duration_seconds }}
    if: always()
    env:
      CODEX_CI_MATRIX_JSON: ${{ needs.detect.outputs.ci_matrix }}
      CODEX_CI_REQUIRED_SECRETS: ${{ needs.detect.outputs.required_secrets }}
      CODEX_CI_REQUIRED_SECRETS_COUNT: ${{ needs.detect.outputs.required_secrets_count }}
      CODEX_NOTIFY_WEBHOOK: ${{ secrets.CODEX_NOTIFY_WEBHOOK || vars.CODEX_NOTIFY_WEBHOOK || '' }}
      CODEX_PR_COMMENT_ENABLED: ${{ vars.CODEX_PR_COMMENT_ENABLED || 'true' }}
      CODEX_SKIP_CI: ${{ needs.detect.outputs.skip_ci }}
      CODEX_SKIP_REASON: ${{ needs.detect.outputs.skip_reason }}
      CODEX_PRUNED_LANGUAGES_JSON: ${{ needs.detect.outputs.pruned_languages }}
      CODEX_HISTORY_RETENTION: ${{ vars.CODEX_HISTORY_RETENTION || '200' }}
      CODEX_PRUNED_LANGUAGES_JSON: ${{ needs.detect.outputs.pruned_languages }}
    steps:
      - name: Download CI artifacts
        uses: actions/download-artifact@v4
        with:
          path: codex-ci-artifacts
          pattern: codex-ci-*
          merge-multiple: true
          if-no-files-found: ignore
        continue-on-error: true
      - name: Aggregate matrix reports
        id: aggregate
        run: |
          python - <<'PY'
import json
import os
import pathlib

matrix_json = os.environ.get("CODEX_CI_MATRIX_JSON", "[]")
try:
    matrix = json.loads(matrix_json)
except json.JSONDecodeError:
    matrix = []

skip_ci_env = os.environ.get("CODEX_SKIP_CI", "false").lower() == "true"
skip_reason_env = os.environ.get("CODEX_SKIP_REASON", "")
pruned_languages_json = os.environ.get("CODEX_PRUNED_LANGUAGES_JSON", "[]")
try:
    pruned_languages = json.loads(pruned_languages_json)
    if not isinstance(pruned_languages, list):
        pruned_languages = []
except json.JSONDecodeError:
    pruned_languages = []

history_prev_path = pathlib.Path("codex-ci-history/history.jsonl")
history_entries: list[dict] = []
if history_prev_path.exists():
    for line in history_prev_path.read_text(encoding="utf-8").splitlines():
        if not line.strip():
            continue
        try:
            history_entries.append(json.loads(line))
        except json.JSONDecodeError:
            continue

artifacts_root = pathlib.Path("codex-ci-artifacts")
reports = []
telemetry_dest_dir = pathlib.Path("codex-ci-aggregate/telemetry")
telemetry_dest_dir.mkdir(parents=True, exist_ok=True)
if artifacts_root.exists():
    for report_path in artifacts_root.rglob("report.json"):
        try:
            data = json.loads(report_path.read_text(encoding="utf-8"))
        except Exception as exc:
            reports.append({"label": report_path.name, "status": "error", "error": str(exc)})
            continue
        reports.append(data)
    for telemetry_path in artifacts_root.rglob("telemetry.json"):
        parent = telemetry_path.parent
        label_component = parent.name
        if parent.name == "ci" and parent.parent.name == ".codex" and len(telemetry_path.parents) >= 3:
            label_component = telemetry_path.parents[2].name
        if label_component.startswith("codex-ci-"):
            label_component = label_component[len("codex-ci-"):]
        dest_dir = telemetry_dest_dir / (label_component or "default")
        dest_dir.mkdir(parents=True, exist_ok=True)
        (dest_dir / telemetry_path.name).write_text(telemetry_path.read_text(encoding="utf-8"))
    for telemetry_root in artifacts_root.rglob("telemetry"):
        if not telemetry_root.is_dir():
            continue
        label_component = telemetry_root.parent.name
        if label_component.startswith("codex-ci-"):
            label_component = label_component[len("codex-ci-"):]
        dest_dir = telemetry_dest_dir / (label_component or "default")
        dest_dir.mkdir(parents=True, exist_ok=True)
        for telemetry_path in telemetry_root.glob("*.json"):
            (dest_dir / telemetry_path.name).write_text(telemetry_path.read_text(encoding="utf-8"))

index = {}
for entry in matrix:
    label = entry.get("label") or "default"
    index[label] = {"matrix": entry, "status": "missing"}

current_history_entries = []
github_run_id = os.environ.get("GITHUB_RUN_ID")
github_run_attempt = os.environ.get("GITHUB_RUN_ATTEMPT")
github_sha = os.environ.get("GITHUB_SHA")
github_ref = os.environ.get("GITHUB_REF")
timestamp_utc = os.environ.get("GITHUB_RUN_STARTED_AT") or os.environ.get("CI_TIMESTAMP")

for report in reports:
    label = report.get("matrix", {}).get("label") or report.get("matrix_label") or "default"
    status = report.get("overall_status") or report.get("status") or "unknown"
    index.setdefault(label, {"matrix": {"label": label}, "status": status})
    index[label].update({
        "status": status,
        "exit_status": report.get("exit_status"),
        "report": report,
        "duration_ms": report.get("duration_ms") or 0,
    })
    current_history_entries.append({
        "run_id": github_run_id,
        "run_attempt": github_run_attempt,
        "sha": github_sha,
        "ref": github_ref,
        "timestamp": timestamp_utc or report.get("timestamp"),
        "label": label,
        "status": status,
        "exit_status": report.get("exit_status"),
        "duration_ms": report.get("duration_ms"),
        "skip_reason": report.get("skip_reason"),
        "pruned_languages": report.get("pruned_languages"),
        "languages": report.get("profile", {}).get("languages", []),
        "steps": report.get("steps", []),
    })

overall_status = "success"
failed_labels = []
missing_labels = []
aggregate_duration_ms = 0
for label, entry in index.items():
    status = entry.get("status")
    if status not in {"success", "skipped"}:
        overall_status = "failed"
        failed_labels.append(label)
    if status == "missing":
        missing_labels.append(label)
    aggregate_duration_ms += entry.get("duration_ms") or 0

# Build historical telemetry
history_dir = pathlib.Path("codex-ci-aggregate")
history_dir.mkdir(parents=True, exist_ok=True)
history_path = history_dir / "history.jsonl"

combined_history = history_entries + current_history_entries
try:
    max_history = max(1, int(os.environ.get("CODEX_HISTORY_RETENTION", "200")))
except ValueError:
    max_history = 200
if len(combined_history) > max_history:
    combined_history = combined_history[-max_history:]
with history_path.open("w", encoding="utf-8") as fh:
    for entry in combined_history:
        fh.write(json.dumps(entry) + "\n")

# Flaky detection (simple heuristic: step toggles between success and failure in last 5 runs)
flaky_steps = set()
history_by_label = {}
for entry in combined_history:
    history_by_label.setdefault(entry["label"], []).append(entry)

for label, entries in history_by_label.items():
    recent = entries[-5:]
    step_status_map = {}
    for record in recent:
        for step in record.get("steps", []):
            name = step.get("name")
            if not name:
                continue
            step_status_map.setdefault(name, set()).add(step.get("status"))
    for step_name, statuses in step_status_map.items():
        if "failure" in statuses and len(statuses) > 1:
            flaky_steps.add(f"{label}:{step_name}")

summary_lines = [
    "# Codex CI Aggregate",
    "",
    f"*Overall:* **{overall_status.upper()}**",
    f"*Matrix entries:* {len(index)}",
]
if missing_labels:
    summary_lines.append(f"*Missing reports:* {', '.join(sorted(missing_labels))}")
if failed_labels:
    summary_lines.append(f"*Failed labels:* {', '.join(sorted(failed_labels))}")
if not index:
    reason_map = {
        "no_changes": "no changes detected",
        "docs_only": "docs-only changes",
        "no_matching_targets": "no language targets matched changes",
        "config": "configuration rules"
    }
    readable = reason_map.get(skip_reason_env, "no entries to execute")
    summary_lines.append("")
    summary_lines.append(f"CI matrix skipped ({readable}).")
elif skip_ci_env:
    summary_lines.append("")
    summary_lines.append("CI matrix executed despite skip flag (override in effect).")

if pruned_languages:
    summary_lines.append("")
    summary_lines.append(f"*Languages pruned by change filters:* {', '.join(pruned_languages)}")

if aggregate_duration_ms:
    summary_lines.append("")
    summary_lines.append(f"*Total duration:* {aggregate_duration_ms/1000:.3f}s")

if flaky_steps:
    summary_lines.append("")
    summary_lines.append(f"*Flaky steps (last 5 runs):* {', '.join(sorted(flaky_steps))}")

summary_lines.extend([
    "",
    "| Label | Status | Exit | Duration (s) | Languages | Notes |",
    "| --- | --- | --- | --- | --- | --- |",
])

for label, entry in sorted(index.items()):
    status = entry.get("status", "missing")
    exit_status = entry.get("exit_status")
    report = entry.get("report", {})
    languages = report.get("profile", {}).get("languages", [])
    duration_ms = entry.get("duration_ms") or 0
    notes = []
    if report.get("skip_reason"):
        notes.append(f"skip:{report['skip_reason']}")
    pruned = report.get("pruned_languages") or []
    if pruned:
        notes.append("pruned:" + ",".join(pruned))
    if report.get("force_ci"):
        notes.append("forced")
    flaky_for_label = [s.split(":", 1)[1] for s in flaky_steps if s.startswith(f"{label}:")]
    if flaky_for_label:
        notes.append("flaky:" + ",".join(sorted(flaky_for_label)))
    note_text = ", ".join(notes)
    summary_lines.append(
        f"| {label} | {status} | {exit_status if exit_status is not None else 'n/a'} | {duration_ms/1000:.3f} | {', '.join(languages) if languages else 'n/a'} | {note_text} |"
    )

aggregate_dir = pathlib.Path("codex-ci-aggregate")
aggregate_dir.mkdir(parents=True, exist_ok=True)
(aggregate_dir / "summary.md").write_text("\n".join(summary_lines), encoding="utf-8")
(aggregate_dir / "reports.json").write_text(json.dumps(index, indent=2), encoding="utf-8")

outputs = {
    "overall": overall_status,
    "failed": json.dumps(failed_labels),
    "missing": json.dumps(missing_labels),
    "skip_ci": "true" if skip_ci_env else "false",
    "skip_reason": skip_reason_env,
    "pruned_languages": json.dumps(pruned_languages),
    "total_duration_seconds": f"{aggregate_duration_ms/1000:.3f}",
    "flaky_steps": json.dumps(sorted(flaky_steps)),
}

with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as fh:
    for key, value in outputs.items():
        fh.write(f"{key}={value}\n")

(aggregate_dir / "status.json").write_text(json.dumps(outputs, indent=2), encoding="utf-8")
PY
      - name: Publish aggregate summary
        if: always()
        run: |
          if [ -f codex-ci-aggregate/summary.md ]; then
            cat codex-ci-aggregate/summary.md >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload aggregate artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: codex-ci-aggregate
          path: codex-ci-aggregate/**
        continue-on-error: true
      - name: Upload telemetry history
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: codex-ci-history
          path: codex-ci-aggregate/history.jsonl
        continue-on-error: true
      - name: Comment summary on PR
        if: env.CODEX_PR_COMMENT_ENABLED == 'true' && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summaryPath = 'codex-ci-aggregate/summary.md';
            if (!fs.existsSync(summaryPath)) {
              console.log('Summary missing, skipping comment');
              return;
            }
            const body = fs.readFileSync(summaryPath, 'utf8');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body,
            });
      - name: Send webhook notification
        if: env.CODEX_NOTIFY_WEBHOOK != '' && steps.aggregate.outputs.overall != 'success'
        run: |
          status=$(cat codex-ci-aggregate/status.json)
          payload=$(jq -n --arg repo "$GITHUB_REPOSITORY" --arg ref "$GITHUB_REF" --argjson status "$status" '{repository:$repo, ref:$ref, status:$status}')
          curl -sSf -X POST -H 'Content-Type: application/json' \
            --data "$payload" "$CODEX_NOTIFY_WEBHOOK"
        continue-on-error: true
      - name: Fail on CI failures
        if: steps.aggregate.outputs.overall != 'success'
        run: |
          echo "Codex CI matrix reported failures."
          cat codex-ci-aggregate/summary.md || true
          exit 1
  auto-deploy:
    needs:
      - detect
      - auto-ci
      - report
    runs-on: ubuntu-latest
    env:
      CODEX_CI_REQUIRED_SECRETS: ${{ needs.detect.outputs.required_secrets }}
      CODEX_CI_REQUIRED_SECRETS_COUNT: ${{ needs.detect.outputs.required_secrets_count }}
      CODEX_CI_HAS_HOOKS: ${{ needs.detect.outputs.has_ci_hooks }}
      CODEX_CI_HOOK_COUNT: ${{ needs.detect.outputs.ci_hook_count }}
      CODEX_DETECT_DEPLOY_ENABLED: ${{ needs.detect.outputs.deploy_enabled }}
      CODEX_DETECT_HOOKS_DEPLOY_ENABLED: ${{ needs.detect.outputs.hooks_deploy_enabled }}
      CODEX_CHANGED_FILES_JSON: ${{ needs.detect.outputs.changed_files }}
      CODEX_SKIP_REASON: ${{ needs.detect.outputs.skip_reason }}
      CODEX_PRUNED_LANGUAGES_JSON: ${{ needs.report.outputs.pruned_languages }}
      CODEX_TOTAL_DURATION_SECONDS: ${{ needs.report.outputs.total_duration_seconds }}
      CODEX_FLAKY_STEPS_JSON: ${{ needs.report.outputs.flaky_steps }}
      CODEX_CD_ENABLED: ${{ env.CODEX_CD_ENABLED }}
      CODEX_CD_BRANCH: ${{ env.CODEX_CD_BRANCH }}
      CODEX_CD_TARGET: ${{ env.CODEX_CD_TARGET }}
      CODEX_CD_ALLOW_TAGS: ${{ env.CODEX_CD_ALLOW_TAGS }}
    if: >
      needs.auto-ci.result == 'success' &&
      needs.detect.outputs.deploy_enabled == 'true' &&
      needs.detect.outputs.skip_ci != 'true' &&
      needs.report.outputs.skip_ci != 'true' &&
      needs.detect.outputs.has_cd == 'true' &&
      env.CODEX_CD_ENABLED == 'true' &&
      needs.report.outputs.overall == 'success' &&
      (
        (startsWith(github.ref, 'refs/tags/') && env.CODEX_CD_ALLOW_TAGS == 'true') ||
        github.ref == format('refs/heads/{0}', env.CODEX_CD_BRANCH)
      ) &&
      needs.detect.outputs.deploy_hook_count != '0'
    steps:
      - uses: actions/checkout@v4
      - name: Summarise deploy gates
        run: |
          echo "CD enabled (env): ${CODEX_CD_ENABLED}"
          echo "Deploy enabled (config + scripts): ${CODEX_DETECT_DEPLOY_ENABLED}"
          echo "Allowed branch: ${CODEX_CD_BRANCH}"
          echo "Allow tags: ${CODEX_CD_ALLOW_TAGS}"
          echo "Deploy hook count: ${{ needs.detect.outputs.deploy_hook_count }}"
          echo "Deploy hooks enabled (config): ${CODEX_DETECT_HOOKS_DEPLOY_ENABLED}"
          echo "Required secrets (count): ${CODEX_CI_REQUIRED_SECRETS_COUNT}"
          if [ -n "${CODEX_CI_REQUIRED_SECRETS:-}" ]; then
            echo "Required secrets list: ${CODEX_CI_REQUIRED_SECRETS}"
          fi
          if [ -n "${CODEX_FLAKY_STEPS_JSON:-}" ]; then
            echo "Flaky steps detected: ${CODEX_FLAKY_STEPS_JSON}"
          fi
          if [ -n "${CODEX_TOTAL_DURATION_SECONDS:-}" ]; then
            echo "Total CI duration: ${CODEX_TOTAL_DURATION_SECONDS}s"
          fi
          echo "Current ref: ${GITHUB_REF}"
      - name: Ensure deploy script executable
        run: chmod +x .codex/ci/auto-deploy.sh
      - name: Run Codex deployment harness
        env:
          CODEX_CI_REQUIRED_SECRETS: ${{ needs.detect.outputs.required_secrets }}
          CODEX_CD_ENABLED: ${{ env.CODEX_CD_ENABLED }}
          CODEX_CD_BRANCH: ${{ env.CODEX_CD_BRANCH }}
          CODEX_CD_TARGET: ${{ env.CODEX_CD_TARGET }}
          CODEX_CD_ALLOW_TAGS: ${{ env.CODEX_CD_ALLOW_TAGS }}
          CODEX_FLAKY_STEPS_JSON: ${{ needs.report.outputs.flaky_steps }}
          CODEX_TOTAL_DURATION_SECONDS: ${{ needs.report.outputs.total_duration_seconds }}
        run: ./.codex/ci/auto-deploy.sh
      - name: Publish deploy summary
        if: always()
        run: |
          if [ -f .codex/ci/deploy-report.md ]; then
            cat .codex/ci/deploy-report.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "Codex deploy harness did not produce a markdown summary." >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload deploy logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: codex-cd-logs
          path: |
            .codex/ci/deploy-report.*
            .codex/ci/**/*.log
        continue-on-error: true
          skip_docs_only = config_bool("ci.skip_docs_only", True)
          docs_only_env = os.environ.get("CODEX_DOCS_ONLY", "false").lower() == "true"
          no_changes_env = os.environ.get("CODEX_NO_CHANGES", "false").lower() == "true"
